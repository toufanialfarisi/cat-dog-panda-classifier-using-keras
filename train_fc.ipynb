{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Install Library Open CV dan imutils</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Import library</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library keras\n",
    "import keras\n",
    "\n",
    "# import library open computer vision\n",
    "import cv2\n",
    "\n",
    "# import library komputasi numerik\n",
    "import numpy as np\n",
    "\n",
    "# import ilbrary pendukung open cv untuk keperluan manajemen data\n",
    "from imutils import paths\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load gambarnya</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siapkan variabel kosong untuk menampung gambarnya\n",
    "data = []\n",
    "\n",
    "# siapkan variabel kosong untuk menampung label yang akan diprediksi\n",
    "labels = []\n",
    "\n",
    "\n",
    "# load dataset gambarnya dari path 'dataset/animals/'\n",
    "dataset_path = 'datasets/animals/'\n",
    "imagePaths = sorted(list(paths.list_images(dataset_path)))\n",
    "\n",
    "# gambarnya dibuat random (shuffle)\n",
    "random.seed(2)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# masukan data gambar hasil load tadi satu persatu ke dalam variabel data yang kosong tadi\n",
    "for imagePath in imagePaths:\n",
    "    \n",
    "    # baca gambarnya\n",
    "    img = cv2.imread(imagePath)\n",
    "    \n",
    "    # ubah gambarnya ke dalam grayscale (hitam putih) agar memiliki 1 channel (1-dimensional)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # ubah ukuran / dimensi gambarnya menjadi 32x32 px, serta convert ke dalam format vektor\n",
    "    img_flat = cv2.resize(img_gray, (32,32)).flatten()\n",
    "    \n",
    "    # simpan / tumpuk gambar yang sudah dibaca tadi\n",
    "    data.append(img_flat)    \n",
    "    \n",
    "    # baca labelnya dengan melihat path foldernya\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    \n",
    "    # simpan / tumpuk label yang sudah dibaca tadi \n",
    "    labels.append(label)\n",
    "\n",
    "# ubah data label tadi menjadi format array agar lebih memudahkan dalam komputasi\n",
    "lbl = np.array(labels)\n",
    "\n",
    "# ubah var data menjadi array numpy agar lebih memudahkan dalam komputasi\n",
    "dt = np.array(data, dtype='float32')\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lihat salah satu gambarnya</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library matplotlib untuk melihat gambarnya\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# coba kita lihat sebuah gambar pada indeks ke-2 pada iamgePaths\n",
    "gambar = imagePaths[2]\n",
    "\n",
    "# baca gambarnya\n",
    "gbr = cv2.imread(gambar)\n",
    "gbr = cv2.resize(gbr, (100,100))\n",
    "\n",
    "# tambahkan judul yang dilengkapi dengan nama file gambarnya + dimensi asli gambarnya \n",
    "plt.title('gambar = '+str(gambar.split('/')[3])+' ; ukuran = '+str(gbr.shape))\n",
    "\n",
    "# munculkan \n",
    "plt.imshow(gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Cek ukuran / dimensi gambarnya berapa</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dimensi        : ', dt.shape)\n",
    "print('jumlah gambar  : ', dt.shape[0])\n",
    "print('Ukuran gambar  : ', dt.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3072 didapatkan dari 32 x 32 x 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>pecah data yang sudah diload tadi menjadi 2 bagian yaitu</h4>\n",
    "<h4>1) bagian train</h4>\n",
    "<li>X Train</li>\n",
    "<li>Y Train</li>\n",
    "<h4>2) bagian Test</h4>\n",
    "<li>X Test</li>\n",
    "<li>Y Test</li>\n",
    "<h5>X = data input ; Y = label/output</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library untuk memecah datasetnya menjadi bagian train dan test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# pecah datasetnya dengan jumlah data testing sebanyak 25% dari keseluruhan total data\n",
    "x_train, x_test, y_train, y_test = train_test_split(dt, lbl, \n",
    "                                                    test_size=0.25, \n",
    "                                                    random_state=42)\n",
    "\n",
    "# cek apakah sudah benar atau belum pemecaannya\n",
    "print('x_train : ',x_train.shape)\n",
    "print('x_test  : ', x_test.shape)\n",
    "print('y_train : ', y_train.shape)\n",
    "print('y_test  : ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Lakukan one hot enconding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library untuk melakukan one-hot-encoding dengan memanfaatkan method LabelBinarizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# membuat object construktur\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "# memulai melakukan one-hot-encoding untuk y_train dan y_test\n",
    "y_train_encoded = lb.fit_transform(y_train)\n",
    "y_test_encoded = lb.transform(y_test)\n",
    "\n",
    "# cek nilainya\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisai Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah tipe data gambarnya ke float\n",
    "x_train = x_train.astype('float')\n",
    "x_test = x_test.astype('float')\n",
    "\n",
    "# normalisasi data gambarnya agar setiap nilai pixel memiliki rentang dari 0 sampai 1\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Buat layer NN sederhana saja</h3>\n",
    "<img src=\"https://i.ibb.co/0GyxYhB/nn-9.png\" alt=\"nn-9\" border=\"0\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import layer model sebagai cara memembuat model NN-nya\n",
    "from keras.models import Model\n",
    "\n",
    "# import layer Input dan Linear layer (Dense layer)\n",
    "from keras.layers import Dense, Input, Activation\n",
    "\n",
    "# tentukan jumlah node dari input layer dan output layer\n",
    "data_input  = 32 * 32 * 1\n",
    "data_output = 3\n",
    "\n",
    "# mulai membuat arsitektur NN dengan tipe fully connected layer\n",
    "input_layer    = Input(shape=(data_input, ))\n",
    "hidden_layer_1 = Dense(1024, activation='relu', name='hidden_layer_1')(input_layer)\n",
    "hidden_layer_2 = Dense(512, activation='relu', name='hidden_layer_2')(hidden_layer_1)\n",
    "output_layer   = Dense(data_output, activation='softmax', name='ouput_layer')(hidden_layer_2)\n",
    "model          = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# lihat ringkasan dari model yang suda kita buat\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Atur jenis loss function, optimizer dan metrics </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library optimizer, sebagai contoh SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# tentukan nilai learning-rate untuk optimizer yang digunakan\n",
    "opt = SGD(lr=0.001)\n",
    "\n",
    "# compile model dan tentukan fungsi loss, optimizer dan metriks pengujian model yang akan dilatih\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Mulai training dengan 20 iterasi </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memulai pelatihan\n",
    "history = model.fit(x_train, y_train_encoded, \n",
    "                     validation_data=(x_test, y_test_encoded),\n",
    "                     batch_size=32, \n",
    "                     epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lihat hasil ujiannya (evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metode classification report untuk melihat kinerja model yang dihasilkan\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ambil nilai akurasinya\n",
    "akurasi = model.evaluate(x_test, y_test_encoded)[0]\n",
    "\n",
    "# ambil nilai loss-nya\n",
    "loss = model.evaluate(x_test, y_test_encoded)[1]\n",
    "\n",
    "# tampilkan akurasi dan lossnya\n",
    "print()\n",
    "print('akurasi : %.2f%%' % (akurasi))\n",
    "print('loss    : %.2f%%' % loss, '\\n')\n",
    "\n",
    "# tampilkan laporan kinerja modelnya\n",
    "prediksi = model.predict(x_test)\n",
    "print(classification_report(y_test_encoded.argmax(axis = 1), prediksi.argmax(axis = 1), target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Lihat grafik akurasi dan loss nya </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nilai-nilai loss-nya\n",
    "loss = history.history['loss']\n",
    "\n",
    "# nilai-nilai val_loss-nya\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# nilai-nilai akurasi-nya\n",
    "acc = history.history['acc']\n",
    "\n",
    "# nilai-nilai val_acc-nya\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# menentukan sumbu x nya dari 0 sampai dengan banyaknya jumlah nilai loss/acc\n",
    "sumbu_x = np.arange(0, len(loss))\n",
    "\n",
    "# memasukan library plotting (matplotlib)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# grafik plot untuk melihat loss\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(sumbu_x, loss, label='loss')\n",
    "plt.plot(sumbu_x, val_loss, label='val_loss')\n",
    "plt.legend()\n",
    "\n",
    "# grafik plot untuk melihat akurasinya\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(sumbu_x, acc, label='acc')\n",
    "plt.plot(sumbu_x, val_acc, label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simpan model dan label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simpan model keras / nn - nya ke dalam format h5\n",
    "model.save('model_fc.h5')\n",
    "\n",
    "# simpan label - nya ke dalam format pickle\n",
    "import pickle\n",
    "f = open('lable.pickle', 'wb')\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library pandas untuk manipulasi struktur datanya\n",
    "import pandas as pd\n",
    "\n",
    "# siapkan list comprehension untuk menampung nilai-nilai actual (sebenarnya) dari y_test\n",
    "arr_y_test = [lb.classes_[y_test_encoded.argmax(1)[i]] for i in range(y_test.shape[0])]\n",
    "\n",
    "# masukan list comprehension yang sudah dibuat ke dalam dataframe dengan pandas\n",
    "y_test_df = pd.DataFrame(np.array(arr_y_test), columns=['y_test'])\n",
    "\n",
    "# siapkan list comprehension untuk menampung nilai-nilai hasil prediksi\n",
    "arr_pred_df = [lb.classes_[i] for i in model.predict(x_test).argmax(1)]\n",
    "\n",
    "# masukan list comprehension yang sudah dibuat ke dalam dataframe \n",
    "pred_df = pd.DataFrame(np.array(arr_pred_df), columns=['prediksi'])\n",
    "\n",
    "# gabungkan antara data nilai sebenarnya dengan hasil prediksi\n",
    "perbandingan = y_test_df.join(pred_df, how='left')\n",
    "\n",
    "# lihat perbandingannya\n",
    "perbandingan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
